dataset:
  path: ../../input/ai-hackaton
  train: final_train.csv
  test: final_test.csv

model:
  fold: 5
  verbose: 100

params:
  reg_alpha: 1.0997191680377813e-05
  reg_lambda: 0.04104630401883339
  max_depth: 15
  num_leaves: 191
  colsample_bytree: 0.5198042692950159
  subsample: 0.6599641068895281
  subsample_freq: 9
  min_child_samples: 7
  min_child_weight: 0.1
  max_bin: 334
  n_jobs: -1
  n_estimators: 20000
  learning_rate: 0.05
  boosting_type: gbdt
  objective: multiclass
  eval_metric: multi_logloss
  random_state: 42

submit:
  path: ../../submit
  name: feature_xgboost.csv
